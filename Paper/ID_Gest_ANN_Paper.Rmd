---
title: "Identifying Hand Gestures through Myographic Signals via ANN"
author: "Sam Voisin, Eduardo Coronado, Sebastian Knigge, Yuan Zheng"
date: "April 25, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Abstract


## Introduction

Recent advances in surface electromyographic signal (sEMG)
recordingsystems and analytics methods have encouraged the use
of sEMGs in human-machine interfaces to control exoskeletons
and protheses; however, challenges remain. Accurate classification
of user movements is highly variable given the inherent noise
of sEMG recording systems and per-user variability. In turn, this
leads to problems downstream when attempting to convert these
classifications into spatial directions (e.g. up, down, right, and left).
Here, we aim to address the former challenge specifically. Our goal
is to design and implement a light-weight unsupervised learning
model via a multi-layered neural network to accurately identify six
distinct hand gestures from sEMG data.


## Methods

Our analysis workflow was comprised of 4 main phases: preprocessing, dimension reduction via PCA, modeling, and performance comparison as shown in Figure $1$.

![Figure 1: Schematic of overall workflow stages: preprocessing, PCA, modeling and performance comparison](/Graphics/Flow.png)

### Data Preprocessing

We implemented a root means squared (RMS) envelope of $200$ ms overlapping time windows at $100$ $ms$ steps via the biosignalEMG R package to remove some of the noise generated during sEMG signal collection.

### Dimension Reduction

Dimension reduction was done via a principal component analysis (PCA) of the 8 distinct channels used to record sEMG data in order to reduce the training time of the neuronal network. We achieved this via the R princomp function that performs a spectral decomposition of the gesture design matrix.

### Modeling

The final step of preprocessing requires adding "padding" to the end of each gesture's data matrix. This is done so that the vectors passed into the models are of the same dimension.We then developed two Artificial Neural Networks (ANN), one with all components and a second with a subset selected during the dimension reduction stage (Figure $2$). Each of these has a single hidden layer with eight hidden nodes having linear activation. These eight nodes feed into six output nodes with a soft-max activation function. This model was inspired by Lobov et al ($2018$).


## Results

### PCA Analysis

Using the spectral decomposition we found that only $4$ of the $8$ principal components in our dataset contributed meaningfully to variance in our response. From figure $3$, we can see that these $4$ components account for approximately $80%$ of the variability we are seeing to model.

![Figure 3: PCA Screeplot and cumulutive variance plot](/Graphics/1-layer-PCA)


### ANN Performance Comparison



## References




















