---
title: "Keras Model Version 1"
author: "Sam Voisin"
date: "4/10/2019"
output: pdf_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)


library(keras)
suppressMessages(library(tidyverse))

```


```{r helperfcns, echo = FALSE}

append_file_names <- function(root) {
  # append names of all files in a dir to root address
  files <- list.files(root)
  res <- paste0(root, files)
  return(res)
}

id_gest_num <- function(fn) {
  # identify the gesture number from the filename
  motif1 <- "gesture_\\d{1}"
  motif2 <- "\\d{1}"
  gsttxt <- stringr::str_extract(fn, motif1)
  gstnum <- as.integer(stringr::str_extract(gsttxt, motif2))
  return(gstnum)
}

```


```{r dataprep, echo = FALSE}

datafiles <- c()
gestures <- 6
channels <- 8

root <- "../PCA_EMG_data_for_gestures/"
subjects <- paste0(root, list.files(root), "/")
datarefs <- purrr::flatten_chr(map(subjects, append_file_names))

ordered_gest_nums <- id_gest_num(datarefs)

# set up tensor dimensions
numobs <- length(ordered_gest_nums)
y_dims <- c(numobs, gestures)
x_dims <- c(numobs, 4280, channels) # every matrix is padded to 4280; 8 channels

# create categorical matrix of one-hot gesture labels
# this is giving me an extra col of zeros? thats why -1 is here
y_mat <- to_categorical(ordered_gest_nums)[, -1]

# x data tensor
x_mat <- array(0, x_dims)

# dplyr tick for progress bar
prog <- progress_estimated(n = numobs)

for (i in 1:numobs) {
  # 2:9 to remove row names col; we should fix this
  single_gest_mat <- data.matrix(read.table(datarefs[i])[, 2:9]) 
  x_mat[i, , ] <- single_gest_mat
  prog$tick()$print()
}

# flatten x_mat tensor into numobs by (gestures x channels)
x_mat <- array_reshape(x_mat, c(numobs, x_dims[2] * x_dims[3]))

# reset x_dims after reshape
x_dims <- dim(x_mat)

```

## Computation Graph

```{r baselineNN}

SingleLayerNN <- keras_model_sequential()
SingleLayerNN %>%
  layer_dense(units = 8, input_shape = x_dims[-1]) %>% # input layerl; specify units and input shape; no activation defaults to linear for now
  layer_dense(units = 6, activation = "softmax") # output layer

summary(SingleLayerNN)

```



```{r loss}

# crossentropy loss with adadelta optimizer for speed of training
SingleLayerNN %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)

```




```{r train}


history <- SingleLayerNN %>% fit(
  x_mat, y_mat, 
  epochs = 30, batch_size = 1, 
  validation_split = 0.2
  )


plot(history)


```