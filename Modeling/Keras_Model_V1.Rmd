---
title: "Keras Model Version 1"
author: "Sam Voisin"
date: "4/10/2019"
output: pdf_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(here)
library(keras)
suppressMessages(library(tidyverse))

```


```{r helperfcns, echo = FALSE}

build_file_name <- function(s, r, n) {
  # build a file reference
  # r is root reference
  # s is subject number
  # n is file number (1 or 2)
  fmotif <- paste0(n, "_clean.csv")
  base_dir <- paste0(r, s, "/")
  files <- list.files(base_dir)
  # get files that include motif (i.e. n_clean.csv)
  finclude <- stringr::str_detect(files, fmotif)
  return(paste0(base_dir, files[finclude]))
}

split_gest_labs <- function(gfs) {
  # split out the labels from each data file
  # gfs is the list of gesture filenames (i.e. gests1 or gests2)
  for (g in gfs) {
    
  }
  
}

create_gest_refs <- function(root) {
  # get file references for all subjects and all gestures
  subjects <- list.files(root)
  resdf <- tibble(
    subject = subjects,
  ) %>% mutate(gests1 = map(subject, build_file_name, root, 1),
               gests2 = map(subject, build_file_name, root, 2))
  return(resdf)
}

```


```{r dataprep, echo = FALSE}

rootname <- "../clean_EMG_data_for_gestures-master/"

fulldataset <- create_gest_refs(rootname)
fulldataset$gests1[3]

```


## Computation Graph

```{r baselineNN}

### NEED TO USE `to_categorical` to get one hot y vectors

SingleLayerNN <- keras_model_sequential()
SingleLayerNN %>%
  layer_dense(units = 8, input_shape = c()) %>% # input layerl; specify units and input shape; no activation defaults to linear for now
  layer_dense(units = 6, activation = "softmax") # output layer

summary(SingleLayerNN)

```



```{r}


SingleLayerNN %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)






```




```{r}




```



```{r tst}

mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- to_categorical(mnist$train$y)
x_test <- mnist$test$x
y_test <- to_categorical(mnist$test$y)


# reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# rescale
x_train <- x_train / 255
x_test <- x_test / 255


model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = 'softmax')

summary(model)


```


```{r}

model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)

```





```{r}



history <- model %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 1, 
  validation_split = 0.2
  )


plot(history)

```


```{r}

model %>% evaluate(x_test, y_test)

```


```{r}

model %>% predict_classes(x_test)

```



















