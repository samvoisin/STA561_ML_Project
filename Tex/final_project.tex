\documentclass{article}
\usepackage{graphicx}
\usepackage{sidecap}
\usepackage{float}
\usepackage{subcaption}
\usepackage{blindtext}
\usepackage{apacite}
\usepackage{colortbl}
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2018

% ready for submission
% \usepackage{neurips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{final_project}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Identifying Hand Gestures through Myographic Signals via ANN}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Eduardo Coronado\ \\
  Duke University \\
  % examples of more authors
  \And
   Sebastian Knigge \\
   Duke University \\
  % Address \\
  % \texttt{email} \\
  \AND
  Sam Voisin \\
  Duke University \\
  % Address \\
  % \texttt{email} \\
  \And
  Yuan Zheng \\
  Duke University \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

% Comments
\newtheorem{com}{Comment}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  \blindtext
\end{abstract}

\section{Introduction}
Recent advances in surface electromyographic signal (sEMG) recordingsystems and analytics methods have encouraged the use of sEMGs in human-machine interfaces to control exoskeletons and protheses; however, challenges remain.\footnote{\cite{Sensorpaper}} Accurate classification of user movements is highly variable given the inherent noise of sEMG recording systems and per-user variability. In turn, this leads to problems downstream when attempting to convert these classifications into spatial directions (e.g. up, down, right, and left). Here, we aim to address the former challenge specifically. Our goal is to design and implement a light-weight unsupervised learning model via a multi-layered neural network to accurately identify six distinct hand gestures from sEMG data.

\section{Methods}
\label{Methods}


\subsection{Workflow Overview}
For this project our workflow was comprised of 4 main phases: preprocessing, dimension reduction via PCA, modeling, and performance comparison as shown in Figure \ref{Flow} below. 

\begin{SCfigure}[][h]
  \centering
  \caption{Schematic of overall workflow stages: preprocessing, PCA, modeling and performance comparison}
  \includegraphics[width=0.5\textwidth]%
    {Graphics/Flow}% picture filename
    \label{Flow}
\end{SCfigure}


\subsection{sEMG Data}
Raw sEMG signal data from 36 individuals was obtained online from Lobov et al \footnote{Ibid}. Two series were recorded per individual, each comprised of signals obtained via 8 equally spaced sensors around the forearm (i.e. channels). For each series, subjects were asked to performed a set of 6 basic hand gestures. Each gesture was performed for 3 seconds with a 3 second pause in between. Gestures classification scheme is shown in Table 1. 

\begin{figure}[!htb]
  \centering
  \captionsetup{labelformat=empty}
\caption{Table 1. sEMG gesture classifications}
  \includegraphics[width=0.8\textwidth]%
    {Graphics/table1}% picture filename
\end{figure}



\subsection{Preprocessing}

We implemented a root means squared (RMS) envelope of $200$ ms overlapping time windows at $100$\textit{ms} steps via the \textit{biosignalEMG} R package\footnote{\cite{biosignalEMG}} to remove some of the noise generated during sEMG signal collection. As shown in Figure \ref{fig:Smooth} the pre-processing does help provide a means to generate clearer signals that show distinct patterns from each channel per gesture

\begin{figure}[H]
  \centering
  \caption{Schematic of overall workflow stages: preprocessing, PCA, modeling and performance comparison}
  \includegraphics[width=0.9\textwidth]%
    {Graphics/smooth_ex}% picture filename
    \label{fig:Smooth}
\end{figure}

Subsequently, the data was separated according to the gesture classifications (1-6) provided for each time step for further analysis.

\subsection{Dimension Reduction}

Dimension reduction for each gesture was done via a principal component analysis (PCA) of the 8 distinct channels used to record sEMG data in order to identify the most relevant channels for gesture classification and potentially  reduce the training time of the neuronal network. We achieved this via the R \textit{princomp} function that performs a spectral decomposition via singular value decomposition (1) of the gesture design matrix ($\mathbf{X}$)
\begin{equation}
\mathbf{X = U D V'}
\end{equation}
were $U$ and $V$ are the row and column space eigen vectors and $D$ is a diagonal matrix with the eigen values.

\subsection{Modeling}

Before fitting an Artificial Neural Network (ANN) we "padded" the ends of each gesture's data matrix to ensure that the vectors passed into the models are of equal dimension. We then developed two ANN with one hidden layer, the first with all components and a second with channels subset selected during the dimension reduction stage (Figures  \ref{fig:1Layer} and \ref{fig:PCA1Layer}, respectively ). Each of these has a single hidden layer with eight hidden nodes having linear activation. These eight nodes feed into six output nodes with a soft-max activation function. This model was inspired by Lobov et al's approach.\footnote{\cite{Sensorpaper}}

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Graphics/1-layer-NN}
  \caption{Schematic of ANN with all 8 channels }
  \label{fig:1Layer}
\end{subfigure}%
\begin{subfigure}{.6\textwidth}
  \centering
  \includegraphics[width=.7\linewidth]{Graphics/1-layer-PCA-NN}
  \caption{Schematic of ANN with 4 PC channels}
  \label{fig:PCA1Layer}
\end{subfigure}
\caption{Artificial Neuronal Net structures}
\label{gig:Model}
\end{figure}

The  computation graphs for the ANN were generated via an R implementation of Keras\footnote{\cite{Keras}}, which relies on Google's TensorFlow engine for backpropogation. This allowed us to implement a flexible design framework so that we could  add, edit, and remove layers from our models quickly and efficiently during our development process. \\
Afterward, five additional ANN were generated with an increasing number of hidden layers ($l=1,...5$) but only using the principal components as inputs. Figure \ref{fig:5Layers} shows a schematic representation of how each hidden layer was added following a similar process for inputs and outputs as for the initial ANNs.

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{Graphics/1-layer-NN}
\end{subfigure}%
\begin{subfigure}{.6\textwidth}
  \centering
  \includegraphics[width=.9\linewidth]{Graphics/2-layer-NN}
\end{subfigure}
\caption{Increasing number of hidden layers in Artificial Neuronal Net structure}
\label{fig:5Layers}
\end{figure}

\subsection{Performance Assessment}
To assess the performance of each ANN, we used an k-fold cross validation strategy ($k =5$) to split our data to generate a gesture-specific training and a testing sets. These were using the \textit{caret} R package via random sampling. We then assessed the average classification accuracy of each ANN using a categorical cross entropy metric which measures the \textit{Kullback-Leibler} (KL) divergence between the true distribution of the response variable and the distribution of the predictions. This was done for both the initial ANN previously mentioned and shown in Figures \ref{fig:1Layer} and \ref{fig:PCA1Layer}, as well the subsequent ANN with increasing number of layers from Figure \ref{fig:5Layers}.\\
Additionally, our code was timed to assess the computational costs versus gains in accuracy as we increase the number of layers.


\section{Results}

\subsection{Principal Component Analysis}

Using the spectral decomposition we found that only $4$ of the $8$ principal components in our dataset contributed meaningfully to variance in our response. From figure $3$, we can see that these $4$ components account for approximately $80$\% of the variability we are seeking to model.\\
We might be interested in compareable results, or a decision rule which is applicable to different data sets. We introduce a relative measure $\kappa$ which can be used for the PCA of data sets with any dimension.

\[\kappa_i=\frac{{proportional\ explained\ variance}_i}{\frac{1}{{\#\ of\ dimensions}}}\]

One can define a decision rule, which is dempendent on a threshold $\delta$: \textit{Include $PC_i \ \forall \ \kappa_i>\delta$}

For our data set we choose $\delta:=0.6$.

\begin{figure}[H]
  \centering
  \caption{PCA Screeplot and cumulutive variance plot}
  \includegraphics[width=0.9\textwidth]%
    {Graphics/PCA_Plots/PCA_screeplot-150dpi}% picture filename
    \label{fig:PCA}
\end{figure}

% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Do, Apr 25, 2019 - 14:58:37
\begin{table}[!htbp] \centering 
  \caption{PCA measures} 
  \label{} 
\begin{tabular}{@{\extracolsep{0pt}} ccccccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & Comp. 1 & Comp. 2 & Comp. 3 & Comp. 4 & Comp. 5 & Comp. 6 & Comp. 7 & Comp. 8 \\ 
\hline \\[-1.8ex] 
proportion of \\  explained variance & $0.343$ & $0.211$ & $0.132$ & $0.116$ & $0.072$ & $0.055$ & $0.043$ & $0.028$ \\ 
\hline \\
cummulative explained \\ variance & $0.343$ & $0.554$ & $0.686$ & $0.802$ & $0.874$ & $0.929$ & $0.972$ & $1$ \\ 
\hline \\
$\kappa$ & $2.744$ & $1.689$ & $1.056$ & $0.930$ & $0.574$ & $0.437$ & $0.345$ & $0.225$ \\ 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 


By reducing the number of inputs from $8$ smoothed signals to only $4$ principle components, we were able to reduce overfitting in our model prior to ultizing any dropout layers. This reduction in overfitting decreased prediction accuracy in the validation data set only slightly see the \textit{ANN Performance Comparison} section.


\subsection{ANN Performance Comparison}


\begin{center}

From the timing table for every number of layers (layer), we can see that the most time-wasting method is 4 layers ANN, which will take about 556s on the test dataset, while the fastest method is 1 layer ANN, which will take about 300s on the same dataset. It turns out that 5 layers ANN is less time wasting that 4 layers ANN, which only takes about 500s. Considering the remarkable improvement on the performance after using the multiple layers ANN, the little amount of time sacrifice on the computasion is totally acceptable. 
  
\end{center}



\newpage





\bibliographystyle{apacite}
\bibliography{References}



\end{document}
